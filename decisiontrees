Decision Trees
Yorumlama için basit ve kullanışlı yöntemlerden olan Ağaç Tabanlı Yöntemler(Tree Based Methods) yüksek doğruluk, kararlılık ve yorumlanma
kolaylığı ile tahmini modelleri güçlendirir. Verilen belirli bir gözlem için tahmin yapmak amacıyla genellikle eğitim gözlemlerinin
ortalaması ya da ait olduğu bölgedeki modu kullanılır. Tahmini alanı bölmek için kullanılan bölme kuralları kümesi bir ağaçta özetlenebilir
ve bu tip yaklaşımlar karar ağaçları olarak adlandırılır. Karar ağaçlarının otomatik olarak oluşturulması, Morgan & Sonquist (1963) ve 
Morgan & Messenger (1973) tarafından sosyal bilimler alanında yapılan çalışmalara dayanır.
( kaynak1-kitap :W.N. Venables B.D. Ripley Modern Applied Statistics with S-PLUS Third Edition)

Karar ağaçları hem regresyon hem de sınıflandırma problemlerine uygulanabilir. Birden fazla bağımsız parametre ve bir bağımlı parametre
içeren data setinde, bağımlı parametre kategorik ise sınıflandırma ağacı, sürekli yapıda ise regresyon ağacı adını alır.Yani, her bir
gözlemin birçok farklı grup veya sınıftan birinden geldiği bilinmektedir ve amaç etiketlenmemiş gözlemleri sınıflandırmak için öngördürücü
değişkenleri kullanmaktır. Bazı durumlarda, analist hangi öngördürücülerin yanıtla ilişkili olduğunu, bunların nasıl ilişkili olduğunu ve
belki de öngörücü değişkenlerin bile başkaları ile tepki tahmininde nasıl etkileşime girdiğini belirlemek isteyebilir.
(kaynak kitap chapter 5:High-Dimensional Data Analysis in Cancer Research)

Amaç hem kategorik hem nümerik verilerden faydalanarak çıkarılan basit karar kuralları ile bir hedef değişkeninin değerini öngören model
oluşturmaktır.
Karar Ağaçları Terminolojisi
Kök Düğüm: Tüm popülasyonu veya alınmış örneği temsil eder ve iki ya da daha fazla homoje kümeye ayrılır.
Yaprak Düğüm:Düğümler bölünmüyorsa yaprak düğüm adını alır.
Karar Düğümü: Bir alt düğüm başka alt düğümlere ayrılırsa, karar düğümü olarak adlandırılır.
Sınıflandırma ağacı girdi olarak iki dizi alır: alıştırma örnekleri tutan seyrek veya yoğun bir dizi ve boyutu [n_samples, n_features] 
olan X dizisi, alıştırma örnekleri için sınıf etiketlerini tutan ve tamsayı değerler alan Y boyut [n_samples] dizisi.
>>> from sklearn import tree
>>> X = [[0, 0], [1, 1]]
>>> Y = [0, 1]
>>> clf = tree.DecisionTreeClassifier()
>>> clf = clf.fit(X, Y)
>>> clf.predict([[2., 2.]])
array([1])
( http://scikit-learn.org/stable/modules/tree.html )
Veriyi genelleştirmeyen aşırı karmaşık ağaçlar oluşması, verideki küçük bir değişikliğin tamamen farklı bir yapı oluşturması,
öğrenmesi zor kavramlar içermesi gibi nedenler karar ağaçlarının dezavantajlarındandır.
En ayırt edici veriyi belirlemek için bilgi kazancı ölçülür. Bilgi kazancı ölçümünde entropi kullanılır.
Satır sınıflandırmak için gerekli bilgi :  I(s1,s2,...,sm)=-∑i=1,m (si/s)log2(si/s)
Entropi=E(A): ∑[(s1j+...+smj)/s]I(s1j,...,smj)
Kazanç(A)=I(s1,...,sm)-E(A)
(www.ayhandemiriz.com/SakaryaWebSite/slides/DMHafta5.ppt)
