Decision Trees
Yorumlama için basit ve kullanışlı yöntemlerden olan Ağaç Tabanlı Yöntemler(Tree Based Methods) yüksek doğruluk, kararlılık ve 
yorumlanma kolaylığı ile tahmini modelleri güçlendirir. Verilen belirli bir gözlem için tahmin yapmak amacıyla genellikle eğitim 
gözlemlerinin ortalaması ya da ait olduğu bölgedeki modu kullanılır. Tahmini alanı bölmek için kullanılan bölme kuralları kümesi bir
ağaçta özetlenebilir ve bu tip yaklaşımlar karar ağaçları olarak adlandırılır. Karar ağaçlarının otomatik olarak oluşturulması, 
Morgan & Sonquist (1963) ve Morgan & Messenger (1973) tarafından sosyal bilimler alanında yapılan çalışmalara dayanır.
( kaynak1-kitap :W.N. Venables B.D. Ripley Modern Applied Statistics with S-PLUS Third Edition)

Karar ağaçları hem regresyon hem de sınıflandırma problemlerine uygulanabilir. Birden fazla bağımsız parametre ve bir bağımlı parametre
içeren data setinde, bağımlı parametre kategorik ise sınıflandırma ağacı, sürekli yapıda ise regresyon ağacı adını alır.Yani, her bir
gözlemin birçok farklı grup veya sınıftan birinden geldiği bilinmektedir ve amaç etiketlenmemiş gözlemleri sınıflandırmak için
öngördürücü değişkenleri kullanmaktır. Bazı durumlarda, analist hangi öngördürücülerin yanıtla ilişkili olduğunu, bunların nasıl
ilişkili olduğunu ve belki de öngörücü değişkenlerin bile başkaları ile tepki tahmininde nasıl etkileşime girdiğini belirlemek
isteyebilir. (kaynak kitap chapter 5:High-Dimensional Data Analysis in Cancer Research)
Amaç hem kategorik hem nümerik verilerden faydalanarak çıkarılan basit karar kuralları ile bir hedef değişkeninin değerini öngören model
oluşturmaktır.

Karar Ağaçları Terminolojisi
1.Kök Düğüm: Tüm popülasyonu veya alınmış örneği temsil eder ve iki ya da daha fazla homoje kümeye ayrılır.
2.Yaprak Düğüm:Düğümler bölünmüyorsa yaprak düğüm adını alır.
3.Karar Düğümü: Bir alt düğüm başka alt düğümlere ayrılırsa, karar düğümü olarak adlandırılır.
4.Ata ve Çocuk Düğümü:Belli bir düğümün herhangi bir alt düğümüne çocuk düğüm denir ve verilen düğüm sırasıyla çocuğun üstüdür.
5.Alt Ağaç: Ağacın bir alt bölümüne alt ağaç adı verilir.
6.Bölme: Bir düğümün iki veya daha fazla alt düğümlere bölünmesi işlemidir.
Bunlar karar ağaçları için kullanılan yaygın terimlerdir.

Sınıflandırma Ağacı
Sınıflandırma ağaçları (Classification Trees) 1984 yılında Leo Breiman, Jerome Friedman, Richard Olshen ve Charles Stone tarafından
geliştirilen bir yöntemdir. Parametrik olmayan bu yöntem veri madenciliğinde oldukça önemli bir yere sahiptir( kaynak Breiman, L., 2001,
Random forests, Machine Learning, 45, 5-32 p).Parametrik olmayan istatistikler ("dağılımsız istatistikler" de denir), bir popülasyonun
bazı özelliklerini tanımlayabilen, bu nitelik hakkında hipotezleri test edebilen, diğer bir özellikle olan ilişkisini veya zaman içinde
ilgili yapılardaki bu özellikteki farklılıkları test edebilen, popülasyonun veri dağılımı hakkında hiçbir varsayıma ihtiyaç duymayan ve
aralık düzeyinde ölçüm gerektirmeyen bir yöntemdir. (kaynak: http://psych.unl.edu/psycrs/971/nonpar/intro.pdf). Kantitatif bir cevap
yerine nitel bir cevabı tahmin etmek için kullanılan Sınıflandırma Ağaçlarında sınıf daha önceden atanmış bir değerdir.(kaynak: chapter
8.1.2 An Introduction to Statistical Learning with Applications in R ). Bir sınıflandırma ağacı, sıralı bir dizi soruyu sormanın
sonucudur ve dizideki her adımda sorulan soru türü, dizinin önceki sorularına verilen cevaplara bağlıdır.Sınıflandırma ağacında eğitim
verisinde terminal düğüm tarafından elde edilen değer o bölgedeki gözlemlerin modudur. Böylece, görünmeyen bir veri gözlemi o bölgede
düşerse, tahminini mod değeri ile yapacağız. Tahmini alanı belirgin ve çakışmayan bölümlere ayırır. Basit olması adına, bu bölgeleri
yüksek boyutlu kutular olarak düşünebiliriz.Stratejik bölünmeler yapma kararı bir ağacın doğruluğunu büyük ölçüde etkiler. Bölünme, 
kullanıcı tarafından algoritmada tanımlanan bir durdurma kriterine ulaşılana kadar sürer.Bu bölme işlemi durdurma kriterlerine ulaşılana
kadar tamamen yetişmiş ağaçlarda sonlanır.

Bir ağaç, ilk önce tüm gözlemleri içeren bir "kök" düğümü düşünülerek yetiştirilir, bu düğümdeki gözlemler tek bir öngörücü değişkende
bir "bölme" kullanılarak bir sol ve bir sağdaki iki alt nesne düğümünden birine gönderilir( kaynak High-Dimensional Data Analysis in
Cancer Research chapter 5).Bir düğüm, değişken kümesinin alt kümesidir ve bir terminal olabilir veya terminal olmayabilir. Bir
nonterminal (veya ana) düğüm, iki kız düğümüne bölünen bir düğümdür(ikili bölme). Kategorik bir öngördürücü değişkeni için, bir bölme
sola bir alt grup gönderir ve geri kalanını ise sağa gönderir.Bir ağacın bir düğümü iki soyuna bölmek için kullandığı belirli bölme, her
tahmini değişkende olası tüm bölünmeleri göz önüne alarak seçilir. Bazı ölçütlere göre "en iyi" değeri veren tahmin edici ve bölünmüş
kombinasyon, düğümü bölmek için kullanılır. Aynı prosedür, bazen "özyinelemeli bölümleme" olarak adlandırılan soyundan gelen düğümlere
uygulanır.

Veriyi genelleştirmeyen aşırı karmaşık ağaçlar oluşması, verideki küçük bir değişikliğin tamamen farklı bir yapı oluşturması,
öğrenmesi zor kavramlar içermesi gibi nedenler karar ağaçlarının dezavantajlarındandır.
En ayırt edici veriyi belirlemek için bilgi kazancı ölçülür. Bilgi kazancı ölçümünde entropi kullanılır.
Satır sınıflandırmak için gerekli bilgi :  I(s1,s2,...,sm)=-∑i=1,m (si/s)log2(si/s)
Entropi=E(A): ∑[(s1j+...+smj)/s]I(s1j,...,smj)
Kazanç(A)=I(s1,...,sm)-E(A)
(www.ayhandemiriz.com/SakaryaWebSite/slides/DMHafta5.ppt)
